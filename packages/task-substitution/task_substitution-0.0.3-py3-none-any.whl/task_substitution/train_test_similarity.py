# AUTOGENERATED! DO NOT EDIT! File to edit: 05_train_test_similarity.ipynb (unless otherwise specified).

__all__ = ['TrainTestSimilarity']

# Cell
import pandas as pd
import numpy as np

from .data import *
from .model import *
from .external_data import *

# Cell
class TrainTestSimilarity:
    """Class to check whether train and test come from same distribution or not using task substitution"""
    def __init__(self, cat_flds:list=None, ignore_flds:list=None, perf_fn=None, split_args:dict=None, model_args:dict=None):
        self.dataset_args = {'cat_flds': cat_flds,
                             'ignore_flds': ignore_flds
                            }
        self.model_args = model_args
        self.split_args = split_args

        self.perf_fn = perf_fn

    def check(self, X_train, y_train, X_test):
        """Check whether train and test come from same distribution or not."""
        model = Model(**self.model_args)
        fold_runs = model.cv(X_train, y_train, self.perf_fn)

        self.trained_model = model.fit(X_train, y_train)
        pred = self.trained_model.predict(X_test)

        return fold_runs, pred

    def run(self, train, test):
        train_cpy = train.copy()
        test_cpy  = test.copy()

        # create a new column which represents whether instance comes from
        # training set or test set.
        train_cpy = train_cpy.assign(is_test=0)
        test_cpy  = test_cpy.assign(is_test=1)

        # combine train and test datasets
        df_cpy = pd.concat((train_cpy, test_cpy), axis=0)

        # shuffle the dataset
        df_cpy = df_cpy.sample(frac=1.)
        df_cpy.index = np.arange(len(df_cpy))

        # add is_test as new target field for the dataset
        self.dataset_args['target_fld'] = 'is_test'

        # create dataset class
        data = Dataset(df_cpy, **self.dataset_args)

        # label encode categorical variables
        df_cpy = data.preprocess()

        # split the dataset into train and test
        train, test = Dataset.split_train_test(df_cpy, self.split_args)

        # create target variable
        y_train = train[self.dataset_args['target_fld']]
        X_train = train.drop(self.dataset_args['target_fld'], axis=1)

        y_test = test[self.dataset_args['target_fld']]
        X_test = test.drop(self.dataset_args['target_fld'], axis=1)

        # train model to recover missing values
        fold_runs, preds = self.check(X_train, y_train, X_test)

        # test performance
        test_perf = self.perf_fn(y_test, preds)
        print(f'Performance on unseen dataset: {test_perf}')

        return test_perf